{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9ACPtfHWgmIodb07q1xpF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmiraliEsi83/The-CIFAR-10-dataset/blob/main/Resnet18OnCifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mPX3-RmBOnR"
      },
      "outputs": [],
      "source": [
        "!pip install resnet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as tk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "lBm2CRd6BZ77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class ResnetBlock(Model):\n",
        "    \"\"\"\n",
        "    A standard resnet block.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, down_sample=False):\n",
        "        \"\"\"\n",
        "        channels: same as number of convolution kernels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.__channels = channels\n",
        "        self.__down_sample = down_sample\n",
        "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
        "\n",
        "        KERNEL_SIZE = (3, 3)\n",
        "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
        "        INIT_SCHEME = \"he_normal\"\n",
        "\n",
        "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_1 = BatchNormalization()\n",
        "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_2 = BatchNormalization()\n",
        "        self.merge = Add()\n",
        "\n",
        "        if self.__down_sample:\n",
        "            # perform down sampling using stride of 2, according to [1].\n",
        "            self.res_conv = Conv2D(\n",
        "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
        "            self.res_bn = BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        res = inputs\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.bn_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "\n",
        "        if self.__down_sample:\n",
        "            res = self.res_conv(res)\n",
        "            res = self.res_bn(res)\n",
        "\n",
        "        # if not perform down sample, then add a shortcut directly\n",
        "        x = self.merge([x, res])\n",
        "        out = tf.nn.relu(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet18(Model):\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        \"\"\"\n",
        "            num_classes: number of classes in specific classification task.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
        "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        self.init_bn = BatchNormalization()\n",
        "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
        "        self.res_1_1 = ResnetBlock(64)\n",
        "        self.res_1_2 = ResnetBlock(64)\n",
        "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
        "        self.res_2_2 = ResnetBlock(128)\n",
        "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
        "        self.res_3_2 = ResnetBlock(256)\n",
        "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
        "        self.res_4_2 = ResnetBlock(512)\n",
        "        self.avg_pool = GlobalAveragePooling2D()\n",
        "        self.flat = Flatten()\n",
        "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.conv_1(inputs)\n",
        "        out = self.init_bn(out)\n",
        "        out = tf.nn.relu(out)\n",
        "        out = self.pool_2(out)\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
        "            out = res_block(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = self.flat(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "d7-6KGK9BZ6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tk.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "JTsCpZUkBZ5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "TP6ilh-tBZ4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "4yEl1dyrBZ3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "_WF60wIaBZ2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = np.unique(y_train)"
      ],
      "metadata": {
        "id": "b1VAsEgaBZy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(classes)"
      ],
      "metadata": {
        "id": "JO-3KZQEBZpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[22].shape"
      ],
      "metadata": {
        "id": "9Wa-Weh9BZkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[22]);"
      ],
      "metadata": {
        "id": "n7m-SKehBnql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[22]"
      ],
      "metadata": {
        "id": "ECAMudt_Bnnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(x_train)"
      ],
      "metadata": {
        "id": "pohSnSIJBnle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train/255"
      ],
      "metadata": {
        "id": "5QLezPKkBnih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[22]);"
      ],
      "metadata": {
        "id": "EcnTZlUZBnfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "ChUoFmSbBu7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0].shape"
      ],
      "metadata": {
        "id": "RUbtLb-tBu5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = x_test/255"
      ],
      "metadata": {
        "id": "34M-AlPOBu12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_grid = 15\n",
        "l_grid = 15\n",
        "\n",
        "fig, axes = plt.subplots(w_grid,l_grid, figsize=(17,17))\n",
        "axes = axes.ravel()\n",
        "n_training = len(x_train)\n",
        "for i in np.arange(0, w_grid * l_grid):\n",
        "  index = np.random.randint(0, n_training)\n",
        " \n",
        "  axes[i].imshow(x_train[index])\n",
        "  axes[i].set_title(y_train[index], fontsize=10)\n",
        "  axes[i].axis('off')\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "JidG8k40BuzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet18(10)\n",
        "model.build(input_shape = (None,32,32,3))"
      ],
      "metadata": {
        "id": "OuTG8LLlBuwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "4p9BZkDTB8gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.2, random_state=12345)"
      ],
      "metadata": {
        "id": "B2H-HfPBB8dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fxLbblxZB8ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=100, \n",
        "                    validation_data=(x_validate, y_validate))"
      ],
      "metadata": {
        "id": "N3wfyBi5B8XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model.evaluate(x_test,y_test)\n",
        "print(f\"Test accuracy: {evaluation[1]*100:.2f}%\")"
      ],
      "metadata": {
        "id": "GbL4hsidB8R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_classes = model.predict(x_test)\n",
        "len(predicted_classes)"
      ],
      "metadata": {
        "id": "CCTP7neeCHEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_classes[0])\n",
        "y_test[0]"
      ],
      "metadata": {
        "id": "m-DYKEJbCHBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(predicted_classes[0])"
      ],
      "metadata": {
        "id": "UZqPfWNPCG9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[0]"
      ],
      "metadata": {
        "id": "KUua2aBsCG6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(5,5,figsize=(12,12))\n",
        "axes = axes.ravel()\n",
        "print(axes.shape)\n",
        "x_test[0].shape\n",
        "for i in np.arange(0,25):\n",
        "  axes[i].imshow(x_test[i].reshape(28,28))\n",
        "  axes[i].set_title(f\"Prediction Class = {np.argmax(predicted_classes[i]):.1f}\\nTrue class = {y_test[i]}\")\n",
        "\n",
        "\n",
        "  axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.5)"
      ],
      "metadata": {
        "id": "zhKzywffCG3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# swap softmax layer with linear layer \n",
        "layer_idx = utils.find_layer_idx(model, 'predictions')\n",
        "model.layers[-1].activation = tf.keras.activations.linear\n",
        "model = utils.apply_modifications(model)"
      ],
      "metadata": {
        "id": "8cGhza3sCG1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-keras-vis"
      ],
      "metadata": {
        "id": "zIznWjYPCRwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import cm\n",
        "from tf_keras_vis.gradcam import Gradcam"
      ],
      "metadata": {
        "id": "MgyVjE1eCTAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradCam = Gradcam(model, clone =True)"
      ],
      "metadata": {
        "id": "PY1XT1-lCTiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import plt"
      ],
      "metadata": {
        "id": "RnBfcwb-CTfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tf_keras_vis.utils.scores import CategoricalScore\n",
        "\n",
        "score = CategoricalScore([3, 8, 8 , 0])"
      ],
      "metadata": {
        "id": "omNIBzcBCS9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_classes = ['cat', 'ship', 'ship', 'airplain']"
      ],
      "metadata": {
        "id": "mFVuijOHCawR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(x_test)"
      ],
      "metadata": {
        "id": "gOuSujpOCas-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = [x_test[0], x_test[1], x_test[2], x_test[3]]"
      ],
      "metadata": {
        "id": "yYXVNhoNCaqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[3]"
      ],
      "metadata": {
        "id": "xCKqp0-9Canb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[100])\n",
        "# y_test[1]"
      ],
      "metadata": {
        "id": "b9ujgNPTChCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import preprocess_input"
      ],
      "metadata": {
        "id": "XoDTkPKsCg_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_images = preprocess_input(images)"
      ],
      "metadata": {
        "id": "7eqkwGgJCg9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_images"
      ],
      "metadata": {
        "id": "I3cJWns9Cg6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.imshow(x_test[1])\n",
        "y_test[3]"
      ],
      "metadata": {
        "id": "QzkCIDX0Cg3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Heatmap"
      ],
      "metadata": {
        "id": "Eh6xstu1CyG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cam = gradCam(score, input_images, penultimate_layer=-1)"
      ],
      "metadata": {
        "id": "v2rEwewFCnLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "show generated images"
      ],
      "metadata": {
        "id": "mXTlNjINCuvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(nrows = 1, ncols = 4, figsize=(12,4))\n",
        "for i, img_class in enumerate(input_classes):\n",
        "    heatmap = np.uint8(cm.jet(cam[i])[..., :4] * 255)\n",
        "    ax[i].set_title(img_class, fontsize=16)\n",
        "    ax[i].imshow(x_test[i])\n",
        "    ax[i].imshow(heatmap, cmap='jet', alpha=0.2) \n",
        "    ax[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yXOCtdqPCnIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mZFLi0qvCnFo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}